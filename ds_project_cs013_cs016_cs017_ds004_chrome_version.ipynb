{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f170f3e3",
   "metadata": {},
   "source": [
    "# Data Science Web Scraping Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf9dadd",
   "metadata": {},
   "source": [
    "# Flipkart Mobile Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166f1118",
   "metadata": {},
   "source": [
    "## Enrollment\n",
    "\n",
    "#### p23cs013 Sagar B. Patel\n",
    "\n",
    "#### p23cs016 Kushal V. Kela\n",
    "\n",
    "#### p23cs017 Rahul K. Sharma\n",
    "\n",
    "#### p23ds004 Harsh N. Bari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c7cfeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09ca8792",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which takes url and fetch data from web\n",
    "def fetch_data(url, i):\n",
    "    \n",
    "    #For chrome users\n",
    "    headers = {\n",
    "    \"User-Agent\": \"Chrome/96.0.4664.45 Safari/537.36 Edg/96.0.1054.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.5\"}\n",
    "    \n",
    "    #For mozilla users\n",
    "    #headers={'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:66.0) Gecko/20100101 Firefox/66.0'}\n",
    "    \n",
    "    #search request\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    #if request accept\n",
    "    if response.status_code == 200:\n",
    "        \n",
    "        #create soup object, get the html structure\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        #fetch the block of mobile\n",
    "        mobile_block = soup.find('div', class_='_1YokD2 _3Mn1Gg')\n",
    "        \n",
    "        #fetch all mobiles from the mobile block\n",
    "        mobiles = mobile_block.find_all('div', class_='_1AtVbE col-12-12')\n",
    "        \n",
    "        \n",
    "        #traverse each mobile one by one\n",
    "        for mobile in mobiles:\n",
    "            mobile_details = mobile.find('div', class_='_2kHMtA')\n",
    "        \n",
    "            if mobile_details:\n",
    "            \n",
    "                #Get some discription form mobile name\n",
    "                desc = mobile_details.find('div', class_='_4rR01T')\n",
    "                desc = desc.text\n",
    "                \n",
    "                #Name\n",
    "                desc_list = desc.split('(')\n",
    "                name = desc_list[0].strip()\n",
    "                \n",
    "                #Body Description\n",
    "                if len(desc_list) > 1:\n",
    "                    desc_list = desc_list[1].split(',')\n",
    "                    body_desc = desc_list[0].strip()\n",
    "                else:\n",
    "                    body_desc = 'NA'\n",
    "                \n",
    "                \n",
    "            \n",
    "                ratting = mobile_details.find('div', class_='_3LWZlK')\n",
    "                if ratting:\n",
    "                    ratting = ratting.text\n",
    "                else:\n",
    "                    ratting = 'NA'\n",
    "        \n",
    "        \n",
    "        \n",
    "                #Price\n",
    "                price = mobile_details.find('div', class_='_30jeq3 _1_WHN1')\n",
    "                if price:\n",
    "                    price = price.text\n",
    "                    price = price[1:]\n",
    "                else:\n",
    "                    price = 'NA'\n",
    "                \n",
    "                \n",
    "                \n",
    "                #Link\n",
    "                link = mobile_details.find('a', class_='_1fQZEK')\n",
    "                link = link.get('href')\n",
    "                link = \"https://www.flipkart.com\" + link\n",
    "                \n",
    "                \n",
    "                \n",
    "                #Specification\n",
    "                specification = mobile_details.find('div', class_='fMghEO')\n",
    "                sub_spec = specification.find_all('li', class_='rgWa7D')\n",
    "                \n",
    "                \n",
    "                #Storage\n",
    "                storage = sub_spec[0].text.split('|')\n",
    "                \n",
    "                #RAM\n",
    "                if 'RAM' in storage[0]:\n",
    "                    ram = storage[0].strip()\n",
    "                else:\n",
    "                    ram = 'NA'\n",
    "                \n",
    "                #Internal Storage\n",
    "                if len(storage) > 1 and 'ROM' in storage[1]:\n",
    "                    internal_storage = storage[1].strip()\n",
    "                else:\n",
    "                    if 'ROM' in storage[0]:\n",
    "                        internal_storage = storage[0].strip()\n",
    "                    else:\n",
    "                        internal_storage = 'NA'\n",
    "                \n",
    "                #Extended Storage\n",
    "                if len(storage) == 3:\n",
    "                    extended_storage = storage[2].strip()\n",
    "                else:\n",
    "                    extended_storage = 'NA'\n",
    "                \n",
    "                #Screen Size\n",
    "                screen_size = sub_spec[1].text\n",
    "                try:\n",
    "                    st = screen_size.index('(')\n",
    "                    end = screen_size.index(')')\n",
    "                    screen_size = screen_size[st+1: end].strip()\n",
    "                except ValueError:\n",
    "                    screen_size = 'NA'\n",
    "                \n",
    "                \n",
    "                #Camera\n",
    "                camera = sub_spec[2].text.split('|')\n",
    "                \n",
    "                #Back Camera\n",
    "                back_camera = camera[0].strip()\n",
    "                \n",
    "                #Front Camera\n",
    "                if len(camera) == 2:\n",
    "                    front_camera = camera[1].strip()\n",
    "                else:\n",
    "                    front_camera = 'NA'\n",
    "                    \n",
    "                #Battery\n",
    "                if len(sub_spec) > 3 and 'mAh' in sub_spec[3].text:\n",
    "                    battery = sub_spec[3].text\n",
    "                else:\n",
    "                    battery = 'NA'\n",
    "                \n",
    "                \n",
    "                #Processor and Warranty\n",
    "                sub_spec_len = len(sub_spec)\n",
    "                if sub_spec_len == 6:\n",
    "                    warranty = sub_spec[5].text\n",
    "                    processor = sub_spec[4].text\n",
    "                elif sub_spec_len == 5:\n",
    "                    warranty = sub_spec[4].text\n",
    "                    processor = 'NA'\n",
    "                else:\n",
    "                    warranty = 'NA'\n",
    "                    processor = 'NA'\n",
    "                \n",
    "            \n",
    "                #store the fetched data into csv file\n",
    "                i += 1\n",
    "                with open(\"mobile_data.csv\", 'a', newline='') as csv_file:\n",
    "                    writer = csv.writer(csv_file)\n",
    "                    writer.writerow([i, name, body_desc, ram, internal_storage, extended_storage, screen_size, back_camera, front_camera, battery, processor, warranty, ratting, link, price])\n",
    "                \n",
    "        return (True, i)\n",
    "        \n",
    "    #failed to accept request    \n",
    "    else:\n",
    "        print(\"Error Occured: Failed to retrive data\")\n",
    "        return (False, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fba12cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a csv file\n",
    "with open('mobile_data.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    \n",
    "    #Create Header\n",
    "    writer.writerow([\"Sr. No.\", \"Name\", \"Body Description\", \"RAM\", \"Internal Storage\", \"Expandable\", \"Screen Size\", \"Back Camera\", \"Front Camera\", \"Battery\", \"Processor\", \"Warranty\", \"Ratings\", \"Link\", \"Price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbffdd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 scraped sucessfully\n",
      "Page 2 scraped sucessfully\n",
      "Page 3 scraped sucessfully\n",
      "Page 4 scraped sucessfully\n",
      "Page 5 scraped sucessfully\n",
      "Page 6 scraped sucessfully\n",
      "Page 7 scraped sucessfully\n",
      "Page 8 scraped sucessfully\n",
      "Page 9 scraped sucessfully\n",
      "Page 10 scraped sucessfully\n",
      "Page 11 scraped sucessfully\n",
      "Page 12 scraped sucessfully\n",
      "Page 13 scraped sucessfully\n",
      "Page 14 scraped sucessfully\n",
      "Page 15 scraped sucessfully\n",
      "Page 16 scraped sucessfully\n",
      "Page 17 scraped sucessfully\n",
      "Page 18 scraped sucessfully\n",
      "Page 19 scraped sucessfully\n",
      "Page 20 scraped sucessfully\n",
      "Page 21 scraped sucessfully\n",
      "Page 22 scraped sucessfully\n",
      "Page 23 scraped sucessfully\n",
      "Page 24 scraped sucessfully\n",
      "Page 25 scraped sucessfully\n",
      "Page 26 scraped sucessfully\n",
      "Page 27 scraped sucessfully\n",
      "Page 28 scraped sucessfully\n",
      "Page 29 scraped sucessfully\n",
      "Page 30 scraped sucessfully\n",
      "Page 31 scraped sucessfully\n",
      "Page 32 scraped sucessfully\n",
      "Page 33 scraped sucessfully\n",
      "Page 34 scraped sucessfully\n",
      "Page 35 scraped sucessfully\n",
      "Page 36 scraped sucessfully\n",
      "Page 37 scraped sucessfully\n",
      "Page 38 scraped sucessfully\n",
      "Page 39 scraped sucessfully\n",
      "Page 40 scraped sucessfully\n",
      "Page 41 scraped sucessfully\n",
      "\n",
      "Website Scraped Sucessfully\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.flipkart.com/search?q=mobiles&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\"\n",
    "\n",
    "i = 0\n",
    "result, i = fetch_data(url, i)\n",
    "\n",
    "if result:\n",
    "    print(\"Page 1 scraped sucessfully\")\n",
    "else:\n",
    "    print('Some Error Occured')\n",
    "        \n",
    "page_no = 2\n",
    "while page_no <= 41 and result:\n",
    "    url = 'https://www.flipkart.com/search?q=mobiles&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page='\n",
    "    \n",
    "    result, i = fetch_data(url+str(page_no), i)\n",
    "    \n",
    "    if result:\n",
    "        print(\"Page \"+str(page_no)+\" scraped sucessfully\")\n",
    "    else:\n",
    "        print('Some Error Occured')\n",
    "        break\n",
    "        \n",
    "    page_no += 1\n",
    "    \n",
    "if page_no == 42:\n",
    "    print(\"\\nWebsite Scraped Sucessfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
